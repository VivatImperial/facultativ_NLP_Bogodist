{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac49971-bd65-40a3-8fd5-89090e245df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import pipeline\n",
    "import math\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17716be-bf8a-4c94-bb48-a840a1c6f77d",
   "metadata": {},
   "source": [
    "# –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1626d-a36b-48e0-a378-ade7df2403ae",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–∞–±–æ—Ä–æ–≤ \"–ø–∞—Ü–∞–Ω—Å–∫–∏—Ö\" —Ü–∏—Ç–∞—Ç, —Å–ø–∞—Ä—â–µ–Ω–Ω—ã—Ö —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≥—Ä—É–ø–ø –≤–æ –≤–∫–æ–Ω—Ç–∞–∫—Ç–µ –∏ —Å–∞–π—Ç–æ–≤ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfed7753-bb52-4b07-b6ea-9891f228eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open('datasets/serious.txt', encoding='utf-8') as my_file:\n",
    "    for line in my_file:\n",
    "        data.append(line[:-1])\n",
    "\n",
    "with open('datasets/vanilla.txt', encoding='utf-8') as my_file:\n",
    "    for line in my_file:\n",
    "        data.append(line[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18829f11-636c-4dbf-9d35-be9e085bd75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/volk.cleaned.big.txt', encoding='utf-8') as my_file:\n",
    "    for line in my_file:\n",
    "        for i in line.split('^'):\n",
    "            i.replace('\\n', ' ')\n",
    "            data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6695f805-301f-4afc-860f-085418931545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"—Ç–µ–±—è —Ü–µ–Ω—è—Ç —Ç–æ–ª—å–∫–æ —Ç–æ–≥–¥–∞ –∫–æ–≥–¥–∞ –≤ —Ç–µ–±–µ –Ω—É–∂–¥–∞—é—Ç—Å—è\" - –ø—Ä–∏–º–µ—Ä —Ü–∏—Ç–∞—Ç—ã –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n"
     ]
    }
   ],
   "source": [
    "print (f'\"{data[228]}\" - –ø—Ä–∏–º–µ—Ä —Ü–∏—Ç–∞—Ç—ã –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b99c35e7-b9f0-4232-b7ea-ba98a60b88d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3046528 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∞—Ç –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
      "761633 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∞—Ç –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
      "158246699 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n",
      "39590699 - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\n"
     ]
    }
   ],
   "source": [
    "train, val = train_test_split(data, test_size=0.2, random_state=13)\n",
    "\n",
    "print (f'{len(train)} - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∞—Ç –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ')\n",
    "print (f'{len(val)} - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ü–∏—Ç–∞—Ç –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ')\n",
    "\n",
    "train = \". \".join(train)\n",
    "val = \". \".join(val)\n",
    "\n",
    "print (f'{len(train)} - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ')\n",
    "print (f'{len(val)} - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ')\n",
    "\n",
    "with open('datasets/train.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(train)\n",
    "\n",
    "with open('datasets/val.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94a5f355-ab91-41e3-bba5-fd2909b26716",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data, train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8075fe84-c210-4db1-affd-ce0507a4a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'datasets/train.txt'\n",
    "test_path = 'datasets/val.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ce6be-8a19-4b4a-b12f-148263c43c30",
   "metadata": {},
   "source": [
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc99007-c32f-4069-b665-f28ebcf9aa25",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –±—ã–ª–æ —Ä–µ—à–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –°–±–µ—Ä–æ–≤—Å–∫—É—é rugpt3medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d15a1c64-9d8e-49e5-93ba-b8afe60a02dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generator = pipeline('text-generation', model=\"ai-forever/rugpt3medium_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd02e54-ce86-48be-8603-e48530e93763",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = text_generator.model\n",
    "tokenizer = text_generator.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4a5cc-5874-4785-b006-6a310f3fa596",
   "metadata": {},
   "source": [
    "# –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c34daf-8848-4bef-89d1-9306687227d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6126b8d1-4b8d-4c8b-bbf8-2673b91a0227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProjectsPy\\clean_giga_generator\\venv\\Lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(train_path, test_path, tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "     \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator\n",
    "\n",
    "train_dataset, test_dataset, data_collator = load_dataset (train_path,test_path,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01924a-8545-42e2-bf53-8890d592e468",
   "metadata": {},
   "source": [
    "# –§–∞–π–Ω—Ç—é–Ω–∏–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ba8c0fc-45cd-456a-a470-bc52620b7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./–ì–∏–≥–∞–¶–∏—Ç–∞—Ç—ã\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32, \n",
    "    eval_steps = 400, \n",
    "    save_steps=800,\n",
    "    warmup_steps=500,\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7e63f18-fcad-4a31-8a6d-e2bb2d89bbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 1:07:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=3.960201416015625, metrics={'train_runtime': 4074.0953, 'train_samples_per_second': 0.579, 'train_steps_per_second': 0.037, 'total_flos': 547933409771520.0, 'train_loss': 3.960201416015625, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b87c7-2c02-42a3-89c6-cf70719df640",
   "metadata": {},
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2967cd-f426-4738-aea4-1a823848838a",
   "metadata": {},
   "source": [
    "–û—Ü–µ–Ω–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ –ø–æ—Ä–∞–∂–¥–∞—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π - –≤–µ—Å—å–º–∞ —Ç—Ä—É–¥–Ω–∞—è –∑–∞–¥–∞—á–∞. –ù–æ –¥–∞–≤–∞–π—Ç–µ —Ö–æ—Ç—è –±—ã –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ae14755e-0e71-43bd-9a4b-ceaaf70b6962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 29.35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d02d652-09bc-441b-977e-8b8d802001a3",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –ø—Ä–æ—Å—Ç–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–æ—Ä–æ—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –º–æ–¥–µ–ª–∏ - —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –µ—ë —Å –¥—Ä—É–≥–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≥–ª—É–ø–æ, —Ç–∞–∫ –∫–∞–∫ Perplexity —Å—Ç—Ä–æ–≥–æ –ø—Ä–∏–≤—è–∑–∞–Ω–∞ –∫ —Å–ª–æ–≤–∞—Ä—é –º–æ–¥–µ–ª–∏. –ù–æ –≤—Å–µ –∂–µ —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–æ —Å \"–±–µ–Ω—á–º–∞—Ä–∫–æ–º\" –≤ –≤–∏–¥–µ –∑–Ω–∞—á–µ–Ω–∏–π —É–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ —É–º–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö \n",
    "\n",
    "(–Ω–∞–ø—Ä–∏–º–µ—Ä WikiText-103:  https://paperswithcode.com/sota/language-modelling-on-wikitext-103) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140a465d-90ae-48a9-8d48-fc5bc7efd7e7",
   "metadata": {},
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c49c91-0952-4cea-a901-7a86b206f277",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(\"./tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb09268b-0e7d-4253-a01a-9ad7bfa2d667",
   "metadata": {},
   "source": [
    "# –°–æ–∑–¥–∞–¥–∏–º —É–¥–æ–±–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –º–æ–¥–µ–ª—å—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f54c8c9d-b8fa-40f8-b965-215375526224",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen = pipeline('text-generation', model = './–ì–∏–≥–∞–¶–∏—Ç–∞—Ç—ã', tokenizer=\"./tokenizer\")\n",
    "\n",
    "def generate(text, temperature = 1.0, max_length = 20, number_of_samples = 5):\n",
    "    \n",
    "    temperature = float(temperature)\n",
    "    max_length = int(max_length)\n",
    "    number_of_samples = int(number_of_samples)\n",
    "    results = text_gen(text, num_return_sequences=number_of_samples, temperature = temperature, return_full_text=True, min_length = 10, max_length=max_length, do_sample=True)\n",
    "    texts = [i['generated_text'] for i in results]\n",
    "    texts_clean = []\n",
    "    \n",
    "    for number, i in enumerate(texts):\n",
    "\n",
    "        text_with_num = f'{number+1}) ' + i\n",
    "        texts_splitted = text_with_num.split('.')\n",
    "        \n",
    "        if len(texts_splitted)>=2:\n",
    "            texts_clean.append ('.'.join(texts_splitted[:-1]))\n",
    "        else:\n",
    "            texts_clean.append ('.'.join(texts_splitted))\n",
    "\n",
    "    return \"\\n\\n\".join(texts_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef31198d-eab0-44b9-842a-4407977583b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    # –ù–ï–ô–†–û–°–¢–ï–¢–•–ï–ú\n",
    "    \n",
    "    –ù–∞—Å—Ç—Ä–æ–π—Ç–µ —Å–≤–æ–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞—Å—Ç–æ—è—â–∏—Ö –ø–æ—Ü–∞–Ω—Å–∫–∏—Ö —Ü–∏—Ç–∞—Ç —Å –ª–µ–≥–∫–∏–º –æ—Ç—Ç–µ–Ω–∫–æ–º –≤–∞–Ω–∏–ª–∏.\n",
    "    \n",
    "    \"\"\")\n",
    "    \n",
    "    temperature = gr.Textbox(label=\"–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ: 1.0)\", value = \"1.0\", lines=1)\n",
    "    max_len = gr.Textbox(label=\"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞\", value = \"20\", lines=1)\n",
    "    text = gr.Textbox(label=\"–í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç\", value = \"–ù–∞—Å—Ç–æ—è—â–∏–π –ø–∞—Ü–∞–Ω, —ç—Ç–æ —Ç–æ—Ç, –∫—Ç–æ\", lines=1)\n",
    "    number_of_samples = gr.Textbox(label=\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤\", value = \"5\", lines=1)\n",
    "    text_out = gr.Textbox(label=\"–ú–£–î–†–û–°–¢–¨ –û–¢ –ú–û–î–ï–õ–ò\", lines=10)\n",
    "    \n",
    "    btn = gr.Button(value=\"–î–ê–ô –ú–£–î–†–û–°–¢–¨\")\n",
    "    btn.click(generate, inputs=[text, temperature, max_len, number_of_samples], outputs=[text_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "953b2aac-6ddf-4ae1-8eb4-357a8f917fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://52d431c47ba289ad01.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://52d431c47ba289ad01.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b78c63-9202-4f22-ab7f-286e37dcf9fa",
   "metadata": {},
   "source": [
    "# –ê –µ—â—ë –º—ã —ç—Ç–æ –≤—Å–µ –∏ –∑–∞—Ö–æ—Å—Ç–∏–º (–ø–æ—Ç—ã–∫–∞—Ç—å—Å—è –≤ –º–æ–¥–µ–ª—å –º–æ–∂–Ω–æ –ø–æ —Å—Å—ã–ª–∫–µ - –≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e44b21-c0cd-4cb3-b48e-2839e93d9304",
   "metadata": {},
   "source": [
    "## https://huggingface.co/spaces/vivatimperial/NeuralStatham"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348bb61e-82c4-4026-8293-4e67df8ad5d8",
   "metadata": {},
   "source": [
    "–ë–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ö–æ—Å—Ç–∏–Ω–≥ —á–µ—Ä–µ–∑ spaces - –≤–µ–ª–∏–∫–∞—è –≤–µ—â—å"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
